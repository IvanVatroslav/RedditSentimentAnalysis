{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (121.0.6167.85) detected in PATH at C:\\Users\\ivan.zeljeznjak\\Desktop\\chromedriver-win64\\chromedriver.exe might not be compatible with the detected chrome version (122.0.6261.112); currently, chromedriver 122.0.6261.111 is recommended for chrome 122.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "from src.scraping.google_scraping.review_data_saver import ReviewDataSaver\n",
    "from src.scraping.google_scraping.review_extractor import ReviewExtractor\n",
    "from src.scraping.google_scraping.review_loader import ReviewLoader\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from src.scraping.browser_managment.browser_manager import BrowserManager  # Ensure this is the updated BrowserManager\n",
    "from src.scraping.browser_managment.parallel_browser_manager import ParallelBrowserManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from src.scraping.google_scraping import RestaurantListScraper\n",
    "from src.scraping.google_scraping.data_saver import DataSaver\n",
    "\n",
    "from src.scraping.google_scraping.review_interaction_handler import ReviewInteractionHandler\n",
    "city='Zagreb'\n",
    "query=f'Restorani {city}'\n",
    "\n",
    "\n",
    "browser_manager = BrowserManager()\n",
    "review_handler = ReviewInteractionHandler(browser_manager.driver)\n",
    "browser_manager.navigate_to_url(f\"https://www.google.hr/search?q={query}\")\n",
    "review_handler.accept_cookies()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T12:52:19.316120Z",
     "start_time": "2024-03-08T12:52:10.362342Z"
    }
   },
   "id": "2b15b3661d5b1b35",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new content loaded. End of list reached.\n",
      "Warning: Column count mismatch. Please check CSV formats.\n",
      "Saved data to C:\\Users\\ivan.zeljeznjak\\DataspellProjects\\RedditSentimentAnalysis\\data\\Zagreb\\restaurant_list.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "review_handler.navigate_to_restaurant_list()\n",
    "\n",
    "\n",
    "scraper = RestaurantListScraper(browser_manager.driver)\n",
    "# Assume driver has navigated to the restaurant list page\n",
    "df_restaurants = scraper.scrape_restaurants()\n",
    "\n",
    "data_saver = DataSaver(df_restaurants, city)\n",
    "data_saver.save_to_csv()\n",
    "time.sleep(5)\n",
    "browser_manager.close_browser()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T12:54:29.885421Z",
     "start_time": "2024-03-08T12:52:19.320395Z"
    }
   },
   "id": "65b4665dbf0276ee",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "               Restaurant Name\n0                 Health n joy\n1                Restoran Lido\n2    Stella bar & Vip restoran\n3                 Restoran HAS\n4                  superplanty\n..                         ...\n208                    Gajbica\n209         Restoran Uspinjača\n210       Restoran Zinfandel's\n211     Boban caffe & restoran\n212            Lobby Food&Mood\n\n[213 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Restaurant Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Health n joy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Restoran Lido</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Stella bar &amp; Vip restoran</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Restoran HAS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>superplanty</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>208</th>\n      <td>Gajbica</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>Restoran Uspinjača</td>\n    </tr>\n    <tr>\n      <th>210</th>\n      <td>Restoran Zinfandel's</td>\n    </tr>\n    <tr>\n      <th>211</th>\n      <td>Boban caffe &amp; restoran</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>Lobby Food&amp;Mood</td>\n    </tr>\n  </tbody>\n</table>\n<p>213 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_restaurants\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T12:54:29.928386Z",
     "start_time": "2024-03-08T12:54:29.887715Z"
    }
   },
   "id": "b67e0bfbf677d003",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "            Restaurant Name  Last scraping attempt  Last scraping attempt date\n0    Esplanade Zagreb Hotel                    NaN                         NaN\n1                 Fisherija                    NaN                         NaN\n2                    Korica                    NaN                         NaN\n3              Health n joy                    NaN                         NaN\n4             Restoran Lido                    NaN                         NaN\n..                      ...                    ...                         ...\n211                 Gajbica                    NaN                         NaN\n212      Restoran Uspinjača                    NaN                         NaN\n213    Restoran Zinfandel's                    NaN                         NaN\n214  Boban caffe & restoran                    NaN                         NaN\n215         Lobby Food&Mood                    NaN                         NaN\n\n[216 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Restaurant Name</th>\n      <th>Last scraping attempt</th>\n      <th>Last scraping attempt date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Esplanade Zagreb Hotel</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fisherija</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Korica</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Health n joy</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Restoran Lido</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>211</th>\n      <td>Gajbica</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>Restoran Uspinjača</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <td>Restoran Zinfandel's</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>Boban caffe &amp; restoran</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>Lobby Food&amp;Mood</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>216 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to the CSV file\n",
    "file_path = r'C:\\Users\\ivan.zeljeznjak\\DataspellProjects\\RedditSentimentAnalysis\\data\\Zagreb\\restaurant_list.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T12:54:29.974850Z",
     "start_time": "2024-03-08T12:54:29.931659Z"
    }
   },
   "id": "24f7fffed0a442ac",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from src.scraping.google_scraping.review_data_saver import ReviewDataSaver\n",
    "from src.scraping.google_scraping.review_extractor import ReviewExtractor\n",
    "from src.scraping.google_scraping.review_loader import ReviewLoader\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from src.scraping.browser_managment.browser_manager import BrowserManager  # Ensure this is the updated BrowserManager\n",
    "from src.scraping.browser_managment.parallel_browser_manager import ParallelBrowserManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from src.scraping.google_scraping.review_interaction_handler import ReviewInteractionHandler\n",
    "\n",
    "def perform_search(query):\n",
    "    browser_manager = BrowserManager()\n",
    "    review_handler = ReviewInteractionHandler(browser_manager.driver)\n",
    "    review_loader = ReviewLoader(browser_manager.driver)\n",
    "    review_extractor = ReviewExtractor(browser_manager.driver)\n",
    "    attempt_status = 'Failed'  # Default to 'Failed', update to 'Success' if no exceptions occur\n",
    "    attempt_date = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    \n",
    "    try:\n",
    "        browser_manager.navigate_to_url(f\"https://www.google.hr/search?q={query}\")\n",
    "        review_handler.accept_cookies()\n",
    "        review_handler.navigate_to_reviews()\n",
    "        review_loader.load_reviews()  # Load all reviews\n",
    "        review_handler.click_more_buttons()  # Click all \"More\" buttons\n",
    "        reviews_df = review_extractor.collect_reviews()  # Adjust based on actual return type/method\n",
    "        attempt_status = 'Success'\n",
    "\n",
    "        # Success metrics calculations and prints can remain here or be moved as appropriate\n",
    "        loaded_reviews = review_loader.total_loaded_reviews\n",
    "        scraped_reviews = review_extractor.total_scraped_reviews\n",
    "        ratio = scraped_reviews / loaded_reviews if loaded_reviews > 0 else 0\n",
    "        percentage = (scraped_reviews / loaded_reviews * 100) if loaded_reviews > 0 else 0\n",
    "\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Final count of reviews loaded: {loaded_reviews}, Scraped/Loaded Ratio: {scraped_reviews}/{loaded_reviews} = {ratio:.2f}, Success Percentage: {percentage:.2f}%\")\n",
    "        review_data_saver = ReviewDataSaver(reviews_df, query)\n",
    "        review_data_saver.save_reviews_to_csv()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during search for '{query}': {e}\")\n",
    "        attempt_status = 'Failed'\n",
    "    finally:\n",
    "        browser_manager.close_browser()\n",
    "\n",
    "    return query, attempt_status, attempt_date\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T13:43:39.950292Z",
     "start_time": "2024-03-08T13:43:37.546951Z"
    }
   },
   "id": "91c1767148a93120",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from src.scraping.browser_managment.parallel_browser_manager import ParallelBrowserManager\n",
    "\n",
    "# Replace 'src.scraping' with your actual module path\n",
    "\n",
    "city = 'Zagreb'\n",
    "csv_file_path = f'../data/{city}/restaurant_list.csv'\n",
    "df = pd.read_csv(csv_file_path, parse_dates=['Last scraping attempt date'])\n",
    "\n",
    "# Ensure the DataFrame has the necessary columns for tracking scraping attempts\n",
    "if 'Last scraping attempt' not in df.columns:\n",
    "    df['Last scraping attempt'] = 'Not attempted'\n",
    "if 'Last scraping attempt date' not in df.columns:\n",
    "    df['Last scraping attempt date'] = pd.NaT\n",
    "\n",
    "# Filter the DataFrame for restaurants to attempt scraping\n",
    "one_month_ago = datetime.now() - timedelta(days=30)\n",
    "should_scrape = (\n",
    "        (df['Last scraping attempt'] == 'Not attempted') |\n",
    "        (df['Last scraping attempt'] == 'Failed') |\n",
    "        (df['Last scraping attempt date'].isna()) |\n",
    "        (df['Last scraping attempt date'] < one_month_ago)\n",
    ")\n",
    "\n",
    "# Create queries only for those restaurants that meet the conditions\n",
    "queries = [row['Restaurant Name'] + ' ' + city for index, row in df[should_scrape].iterrows()]\n",
    "\n",
    "# Prepare the args_list for the ParallelBrowserManager\n",
    "parallel_manager = ParallelBrowserManager(df, csv_file_path, city, workers=3)\n",
    "\n",
    "\n",
    "\n",
    "args_list = [(query,) for query in queries]\n",
    "results = parallel_manager.perform_parallel_action(perform_search, args_list)\n",
    "\n",
    "# Function to update the DataFrame with the search results\n",
    "def update_dataframe_with_results(df, results, city):\n",
    "    for result in results:\n",
    "        if result:  # Ensure there's a result before processing\n",
    "            query, status, date = result\n",
    "            restaurant_name_with_city = query.rsplit(' ', 1)[0]\n",
    "            # Remove the city name from the result for matching\n",
    "            restaurant_name = restaurant_name_with_city.replace(f' {city}', '').strip()\n",
    "            df.loc[df['Restaurant Name'].str.strip() == restaurant_name, 'Last scraping attempt'] = status\n",
    "            df.loc[df['Restaurant Name'].str.strip() == restaurant_name, 'Last scraping attempt date'] = date\n",
    "\n",
    "\n",
    "# Update the DataFrame with the results\n",
    "update_dataframe_with_results(df, results, city)\n",
    "\n",
    "# Save the updated DataFrame back to CSV\n",
    "df.to_csv(csv_file_path, index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb1f2ff4fa54af7a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#placeholder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T13:22:08.163723Z",
     "start_time": "2024-03-04T13:22:08.153687Z"
    }
   },
   "id": "8b405752d94b76ac",
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "redditsentimentanalysis",
   "language": "python",
   "display_name": "Reddit Sentiment Analysis Env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
